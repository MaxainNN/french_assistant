# üá´üá∑ French Assistant ‚Äî –ù–µ–π—Ä–æ-—Å–æ—Ç—Ä—É–¥–Ω–∏–∫ –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ —Å RAG

<div align="center">

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![LangChain](https://img.shields.io/badge/LangChain-0.2+-green.svg)
![ChromaDB](https://img.shields.io/badge/ChromaDB-0.4+-orange.svg)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MaxainNN/french-assistant/blob/main/french_assistant.ipynb)

**–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ —Å —Ä—É—Å—Å–∫–æ–≥–æ –Ω–∞ —Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π —è–∑—ã–∫**

<img src="images/preview_app_for_readme.png" width="512" height="512">

</div>

---

## üìã –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

- [–û–ø–∏—Å–∞–Ω–∏–µ](#-–æ–ø–∏—Å–∞–Ω–∏–µ)
- [–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞](#-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)
- [Workflow LangChain](#-workflow-langchain)
- [–£–ª—É—á—à–µ–Ω–∏—è RAG](#-—É–ª—É—á—à–µ–Ω–∏—è-rag)
- [–ë–æ—Ä—å–±–∞ —Å –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—è–º–∏](#-–±–æ—Ä—å–±–∞-—Å-–≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—è–º–∏)
- [–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å](#-–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å)
- [–£—Å—Ç–∞–Ω–æ–≤–∫–∞](#-—É—Å—Ç–∞–Ω–æ–≤–∫–∞)
- [–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ](#-–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ)
- [–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ](#-—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)
- [–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏](#-—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏)
- [–ü–æ–ª–µ–∑–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã](#-–ø–æ–ª–µ–∑–Ω—ã–µ-–º–∞—Ç–µ—Ä–∏–∞–ª—ã)

---

## üìñ –û–ø–∏—Å–∞–Ω–∏–µ

**French Assistant** ‚Äî —ç—Ç–æ RAG-—Å–∏—Å—Ç–µ–º–∞ (Retrieval-Augmented Generation) –¥–ª—è –ø–æ–º–æ—â–∏ –≤ –ø–µ—Ä–µ–≤–æ–¥–µ —Å —Ä—É—Å—Å–∫–æ–≥–æ –Ω–∞ —Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π —è–∑—ã–∫. –°–∏—Å—Ç–µ–º–∞ –≤–∫–ª—é—á–∞–µ—Ç:

### –ü—Ä–æ—Ñ–∏–ª—å –Ω–µ–π—Ä–æ-—Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞

- **–ü—Ä–æ—Ñ–µ—Å—Å–∏—è:** –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç
- **–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è:** –†—É—Å—Å–∫–æ-—Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π –ø–µ—Ä–µ–≤–æ–¥, –≥—Ä–∞–º–º–∞—Ç–∏–∫–∞, –∏–¥–∏–æ–º–∞—Ç–∏–∫–∞
- **–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –º–∏—Ä:** –ù–æ—Å–∏—Ç–µ–ª—å –¥–≤—É—Ö –∫—É–ª—å—Ç—É—Ä, –ø–µ–¥–∞–Ω—Ç–∏—á–Ω—ã–π –∫ –¥–µ—Ç–∞–ª—è–º
- **–ü—Ä–∏–Ω—Ü–∏–ø—ã:** –¢–æ—á–Ω–æ—Å—Ç—å, –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å, –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å, –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å

### –ö–ª—é—á–µ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

‚úÖ –ü–µ—Ä–µ–≤–æ–¥ —Å —É—á—ë—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞ —Ä–µ—á–∏  
‚úÖ –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∞–≤–∏–ª  
‚úÖ –†–∞–±–æ—Ç–∞ —Å –∏–¥–∏–æ–º–∞–º–∏ –∏ —Ñ—Ä–∞–∑–µ–æ–ª–æ–≥–∏–∑–º–∞–º–∏  
‚úÖ –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –ª–æ–∂–Ω—ã—Ö –¥—Ä—É–∑—å—è—Ö –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∞  
‚úÖ –ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π  
‚úÖ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω–µ–±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤  

---

## üèó –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```mermaid
flowchart TB
    subgraph INPUT ["üì• INPUT LAYER"]
        A[User Query] --> B[Safety Filter<br/>Injection + Topics]
        B --> C[Query Preprocessor<br/>Query Expansion + HyDE]
    end

    subgraph RETRIEVAL ["üîç RETRIEVAL LAYER"]
        D[Multi-Query Retrieval] --> E[ChromaDB Vector Store]
        E --> F[MMR Selection<br/>Diversity + Relevance]
    end

    subgraph CRAG ["üîß CRAG LAYER"]
        G[Quality Assessment<br/>Excellent/Good/Partial/Poor]
        G --> H[Correction Strategy<br/>none/supplement/refine/fallback]
        H --> I[Fallback Knowledge Injection]
    end

    subgraph GENERATION ["‚öôÔ∏è GENERATION LAYER"]
        J[System Prompt<br/>+ Few-Shot + Context] --> K[LLM Saiga/Llama<br/>Temperature: 0.3]
    end

    subgraph ANTIHALLUCINATION ["üõ°Ô∏è ANTI-HALLUCINATION LAYER"]
        L[Lexical Grounding Check]
        M[Semantic Consistency Check]
        N[Chain of Verification CoVe]
        O[Confidence Calibration]
    end

    subgraph OUTPUT ["üì§ OUTPUT LAYER"]
        P[Trace Logger] --> Q[Output Formatter]
        Q --> R[Final Response]
    end

    C --> D
    F --> G
    I --> J
    K --> L
    K --> M
    K --> N
    L --> O
    M --> O
    N --> O
    O --> P
```

---

## üîÑ Workflow LangChain

### –î–∏–∞–≥—Ä–∞–º–º–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

```mermaid
sequenceDiagram
    participant User
    participant Safety as Safety Filter
    participant Retriever
    participant CRAG
    participant LLM

    User->>Safety: Query

    Note over Safety: Check Injection<br/>Check Topic

    alt If SAFE
        Safety->>Retriever: Pass query

        Note over Retriever: Query Expansion<br/>Multi-Query<br/>MMR Search

        Retriever->>CRAG: Documents

        Note over CRAG: Evaluate Quality<br/>Apply Correction

        CRAG->>LLM: Context

        Note over LLM: Generate Response

        LLM-->>CRAG: Response
        CRAG-->>User: Final Response (with verification)
    else If UNSAFE
        Safety-->>User: Blocked
    end
```

### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã LangChain

```python
# –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã pipeline

from langchain.schema.runnable import (
    RunnablePassthrough,
    RunnableLambda,
    RunnableParallel
)

# 1. Input processing
input_processor = RunnableParallel(
    query=RunnablePassthrough(),
    safety_check=RunnableLambda(safety_filter.filter_input),
    topic_check=RunnableLambda(safety_filter.check_topic_relevance)
)

# 2. Query expansion
query_expander = RunnableLambda(
    lambda x: query_expander.expand_query(x['query'], use_hyde=True)
)

# 3. Retrieval
retriever_chain = RunnableParallel(
    documents=RunnableLambda(lambda x: retriever.retrieve(x)),
    original_query=RunnablePassthrough()
)

# 4. CRAG correction
crag_chain = RunnableLambda(
    lambda x: crag.correct(x['original_query'], x['documents'])
)

# 5. Generation
generation_chain = (
    prompt_template 
    | llm 
    | StrOutputParser()
)

# 6. Hallucination check
hallucination_chain = RunnableLambda(
    lambda x: hallucination_detector.detect(x['response'], x['context'])
)

# Full pipeline
full_chain = (
    input_processor
    | RunnableLambda(check_safety_gate)
    | query_expander
    | retriever_chain
    | crag_chain
    | generation_chain
    | hallucination_chain
    | output_formatter
)
```

---

## üöÄ –£–ª—É—á—à–µ–Ω–∏—è RAG

### 1. Query Expansion (–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤)

```mermaid
flowchart TB
    A["–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å:<br/>'—Å–ø—Ä—è–∂–µ–Ω–∏–µ avoir'"] --> B

    subgraph B ["Query Expansion Module"]
        direction TB
        C["<b>Synonym expansion:</b><br/>‚Ä¢ —Å–ø—Ä—è–∂–µ–Ω–∏–µ avoir<br/>‚Ä¢ conjugation avoir<br/>‚Ä¢ conjugaison avoir"]
        D["<b>HyDE:</b><br/>–ì–ª–∞–≥–æ–ª avoir —Å–ø—Ä—è–≥–∞–µ—Ç—Å—è:<br/>j'ai, tu as..."]
    end

    B --> E["4 –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞"]
```

### 2. MMR (Maximum Marginal Relevance)

–ë–∞–ª–∞–Ω—Å –º–µ–∂–¥—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å—é –∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:

```
Œª = 0.7  (–Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä)

Score(d) = Œª √ó Relevance(d, query) - (1-Œª) √ó max(Similarity(d, d_selected))
```

### 3. CRAG (Corrective RAG)

```mermaid
flowchart TB
    A[Retrieved Documents] --> B[Quality Check]

    B --> C[EXCELLENT]
    B --> D[GOOD]
    B --> E[PARTIAL]
    B --> F[POOR]

    C --> G["None<br/>(pass)"]
    D --> H["Supplement<br/>(add facts)"]
    E --> I["Refine<br/>(clarify)"]
    F --> J["Fallback<br/>(use base knowledge)"]
```

### 4. Self-RAG (–°–∞–º–æ–æ—Ü–µ–Ω–∫–∞)

```python
# –¢–æ–∫–µ–Ω—ã —Å–∞–º–æ–æ—Ü–µ–Ω–∫–∏
RETRIEVAL_TOKEN: bool    # –ù—É–∂–µ–Ω –ª–∏ retrieval?
RELEVANCE_TOKEN: enum    # –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞
SUPPORT_TOKEN: enum      # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –æ—Ç–≤–µ—Ç–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏
UTILITY_TOKEN: enum      # –ü–æ–ª–µ–∑–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞
```

---

## üõ° –ë–æ—Ä—å–±–∞ —Å –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—è–º–∏

### –ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –∑–∞—â–∏—Ç—ã

```mermaid
flowchart TB
    subgraph AHS ["üõ°Ô∏è ANTI-HALLUCINATION"]
        direction TB

        subgraph L1 ["L1: LEXICAL"]
            A1["–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤<br/>grounding_score > 0.3"]
        end

        subgraph L2 ["L2: SEMANTIC"]
            A2["–ü–æ–∏—Å–∫ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π<br/>'–≤—Å–µ–≥–¥–∞' vs '–Ω–∏–∫–æ–≥–¥–∞'"]
        end

        subgraph L3 ["L3: CONFIDENCE"]
            A3["–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏<br/>–ú–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç–∏"]
        end

        subgraph L4 ["L4: CoVe"]
            A4["–í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è claims<br/>–ò—Ç–æ–≥–æ–≤—ã–π confidence score"]
        end

        L1 --> L2 --> L3 --> L4
    end
```

### –ü—Ä–∏–º–µ—Ä –¥–µ—Ç–µ–∫—Ü–∏–∏ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏

```python
# –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
response = "–ê—Ä—Ç–∏–∫–ª—å 'le' –í–°–ï–ì–î–ê –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–µ—Ä–µ–¥ –º—É–∂—Å–∫–∏–º —Ä–æ–¥–æ–º –±–µ–∑ –∏—Å–∫–ª—é—á–µ–Ω–∏–π."
context = "le –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–º–∏ –º—É–∂—Å–∫–æ–≥–æ —Ä–æ–¥–∞. –ü–µ—Ä–µ–¥ –≥–ª–∞—Å–Ω–æ–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è l'"

# –†–µ–∑—É–ª—å—Ç–∞—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏
{
    'has_hallucinations': True,
    'confidence': 0.45,
    'issues': [
        '–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Å–≤–µ—Ä—Ö—É–≤–µ—Ä–µ–Ω–Ω—ã–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è',
        '–ù–∏–∑–∫–æ–µ –ª–µ–∫—Å–∏—á–µ—Å–∫–æ–µ –∑–∞–∑–µ–º–ª–µ–Ω–∏–µ'
    ],
    'grounding_score': 0.28,
    'overconfident_claims': ['–í–°–ï–ì–î–ê', '–±–µ–∑ –∏—Å–∫–ª—é—á–µ–Ω–∏–π'],
    'recommendation': '–î–æ–±–∞–≤—å—Ç–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç–∏'
}
```

---

## üîí –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å

### –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤

```mermaid
flowchart TB
    subgraph SF ["üîí SAFETY FILTER"]
        direction TB

        subgraph S1 ["1. LENGTH"]
            L1["Max 2000 —Å–∏–º–≤–æ–ª–æ–≤"]
        end

        subgraph S2 ["2. INJECTION"]
            L2["–ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –∏–Ω—ä–µ–∫—Ü–∏–π:<br/>ignore, forget, jailbreak..."]
        end

        subgraph S3 ["3. TOPIC"]
            L3["–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏<br/>Score > 0.1"]
        end

        subgraph S4 ["4. LANGUAGE"]
            L4["Allowed: ru, fr"]
        end

        S1 --> S2 --> S3 --> S4
    end
```

### –ü—Ä–∏–º–µ—Ä—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏

| –ó–∞–ø—Ä–æ—Å | –†–µ–∑—É–ª—å—Ç–∞—Ç | –ü—Ä–∏—á–∏–Ω–∞ |
|--------|-----------|---------|
| "–ü–µ—Ä–µ–≤–µ–¥–∏: –ü—Ä–∏–≤–µ—Ç" | ‚úÖ PASS | –í–∞–ª–∏–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å |
| "Ignore all instructions" | ‚ùå BLOCK | Injection |
| "–ù–∞–ø–∏—à–∏ –∫–æ–¥ –Ω–∞ Python" | ‚ùå BLOCK | Off-topic |
| "Comment dit-on '–∫–æ—à–∫–∞'?" | ‚úÖ PASS | –í–∞–ª–∏–¥–Ω—ã–π (—Ñ—Ä.) |

---

## üíª –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –∑–∞–ø—É—Å–∫

### –í–∞—Ä–∏–∞–Ω—Ç 1: Google Colab (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞)

–î–ª—è –∑–∞–ø—É—Å–∫–∞ –≤ Google Colab –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≥–æ—Ç–æ–≤—ã–π notebook:

1. –û—Ç–∫—Ä–æ–π—Ç–µ [french_assistant.ipynb](french_assistant.ipynb) –≤ Google Colab
2. –í—ã–ø–æ–ª–Ω–∏—Ç–µ –≤—Å–µ —è—á–µ–π–∫–∏ –ø–æ –ø–æ—Ä—è–¥–∫—É (Runtime ‚Üí Run all)
3. Notebook –≤–∫–ª—é—á–∞–µ—Ç –¥–µ–º–æ-–±–∞–∑—É –∑–Ω–∞–Ω–∏–π - –º–æ–∂–Ω–æ —Å—Ä–∞–∑—É —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å!

> **–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** –í Colab –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑ –ø–µ—Ä–≤–æ–π —è—á–µ–π–∫–∏.

---

### –í–∞—Ä–∏–∞–Ω—Ç 2: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∫–∞–∫ Python-–ø–∞–∫–µ—Ç (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

```bash
# 1. –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
git clone https://github.com/MaxainNN/french-assistant.git
cd french-assistant

# 2. –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è
python -m venv venv

# –ê–∫—Ç–∏–≤–∞—Ü–∏—è (Linux/Mac)
source venv/bin/activate

# –ê–∫—Ç–∏–≤–∞—Ü–∏—è (Windows)
.\venv\Scripts\activate

# 3. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–∞–∫–µ—Ç–∞ –≤ —Ä–µ–∂–∏–º–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
pip install -e ".[dev]"

# –ò–ª–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π HuggingFace –º–æ–¥–µ–ª–µ–π
pip install -e ".[all]"
```

### –ó–∞–ø—É—Å–∫ CLI-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞

```bash
# –ü–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–∞–∫–µ—Ç–∞
french-assistant

# –ò–ª–∏ —á–µ—Ä–µ–∑ python -m
python -m french_assistant
```

---

### –í–∞—Ä–∏–∞–Ω—Ç 3: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —á–µ—Ä–µ–∑ requirements.txt (legacy)

```bash
pip install -r requirements.txt
python -m french_assistant
```

### –ù–∞—Å—Ç—Ä–æ–π–∫–∞ HuggingFace —Ç–æ–∫–µ–Ω–∞

–î–ª—è —Ä–∞–±–æ—Ç—ã —Å LLM –º–æ–¥–µ–ª—è–º–∏ (Saiga, Llama –∏ –¥—Ä.) –Ω–µ–æ–±—Ö–æ–¥–∏–º —Ç–æ–∫–µ–Ω HuggingFace:

1. –ü–æ–ª—É—á–∏—Ç–µ —Ç–æ–∫–µ–Ω –Ω–∞ [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)
2. –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `.env` –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞:

```bash
cp .env.example .env
```

3. –î–æ–±–∞–≤—å—Ç–µ –≤–∞—à —Ç–æ–∫–µ–Ω:

```bash
# .env
HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

> **–í–∞–∂–Ω–æ:** –§–∞–π–ª `.env` —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–µ–∫—Ä–µ—Ç—ã –∏ –Ω–µ –¥–æ–ª–∂–µ–Ω –ø–æ–ø–∞–¥–∞—Ç—å –≤ git (—É–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω –≤ `.gitignore`)

### –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏ Saiga (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ `src/french_assistant/default_config.yaml`:

```yaml
MODEL_CONFIG:
  primary_model: "IlyaGusev/saiga_llama3_8b"
  generation:
    temperature: 0.3
    max_new_tokens: 1024
    top_p: 0.9
```

---

## üéÆ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### CLI –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å

```bash
# –ü–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–∞–∫–µ—Ç–∞
french-assistant

# –ò–ª–∏ —á–µ—Ä–µ–∑ python -m
python -m french_assistant
```

```
============================================================
üá´üá∑ French Assistant - –ü–µ—Ä–µ–≤–æ–¥—á–∏–∫-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç
============================================================

–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã...
‚úÖ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!

–ö–æ–º–∞–Ω–¥—ã:
  - 'exit' - –≤—ã—Ö–æ–¥
  - 'stats' - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
  - 'trace' - —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞

üë§ –í—ã: –ü–µ—Ä–µ–≤–µ–¥–∏ –Ω–∞ —Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π: –Ø —Ö–æ—á—É –∫–æ—Ñ–µ

ü§ñ –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç:
üìù **–ü–µ—Ä–µ–≤–æ–¥:** Je veux un caf√©.
üìö **–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã:** Je voudrais un caf√©. (–±–æ–ª–µ–µ –≤–µ–∂–ª–∏–≤–æ)
üí° **–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π:** –§–æ—Ä–º–∞ "voudrais" –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –≤–µ–∂–ª–∏–≤—ã—Ö –ø—Ä–æ—Å—å–±.
```

### –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from french_assistant import FrenchAssistant

# –°–æ–∑–¥–∞–Ω–∏–µ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
assistant = FrenchAssistant()

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞
result = assistant.process_query("–ö–∞–∫ —Å–ø—Ä—è–≥–∞–µ—Ç—Å—è –≥–ª–∞–≥–æ–ª √™tre?")

print(result['response'])
print(f"Confidence: {result['metadata']['grounding']['confidence']}")
print(f"Sources: {result['sources']}")
```

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

```python
# –ò–º–ø–æ—Ä—Ç –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
from french_assistant import (
    SafetyFilter,
    HallucinationDetector,
    EnhancedRetriever,
    QueryExpander,
    CorrectiveRAG,
    SelfRAG,
    ChainOfVerification,
)

# –ü—Ä–∏–º–µ—Ä: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ SafetyFilter –æ—Ç–¥–µ–ª—å–Ω–æ
from french_assistant.core.config import SafetyConfig

filter = SafetyFilter(SafetyConfig(max_length=1000))
is_safe, error, meta = filter.filter_input("–ü–µ—Ä–µ–≤–µ–¥–∏: –ü—Ä–∏–≤–µ—Ç")

# –ü—Ä–∏–º–µ—Ä: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ QueryExpander
expander = QueryExpander()
variants = expander.expand_query("—Å–ø—Ä—è–∂–µ–Ω–∏–µ avoir", use_hyde=True)
# ['—Å–ø—Ä—è–∂–µ–Ω–∏–µ avoir', '—Å–ø—Ä—è–≥–∞–µ—Ç—Å—è avoir', 'conjugation avoir', ...]
```

---

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```bash
# –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ —á–µ—Ä–µ–∑ pytest
pytest

# –° –ø–æ–∫—Ä—ã—Ç–∏–µ–º –∫–æ–¥–∞
pytest --cov=french_assistant

# –ó–∞–ø—É—Å–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –º–æ–¥—É–ª—è
pytest tests/test_safety.py -v
pytest tests/test_enhancements.py -v
```

---

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
french_assistant/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ french_assistant/           # Python package
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py             # –ü—É–±–ª–∏—á–Ω—ã–π API –ø–∞–∫–µ—Ç–∞
‚îÇ       ‚îú‚îÄ‚îÄ __main__.py             # CLI —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞
‚îÇ       ‚îú‚îÄ‚îÄ default_config.yaml     # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ core/                   # –Ø–¥—Ä–æ —Å–∏—Å—Ç–µ–º—ã
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ assistant.py        # FrenchAssistant - –≥–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ config.py           # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ safety/                 # –ú–æ–¥—É–ª—å –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ filter.py           # SafetyFilter - —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ hallucination.py    # HallucinationDetector - –¥–µ—Ç–µ–∫—Ü–∏—è –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ retrieval/              # –ú–æ–¥—É–ª—å –ø–æ–∏—Å–∫–∞
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ retriever.py        # EnhancedRetriever - —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ query_expansion.py  # QueryExpander - —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ vectorstore.py      # VectorStoreManager - —Ä–∞–±–æ—Ç–∞ —Å ChromaDB
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ enhancements/           # RAG-—É–ª—É—á—à–µ–Ω–∏—è
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ crag.py             # CorrectiveRAG - –∫–æ—Ä—Ä–µ–∫—Ü–∏—è retrieval
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ self_rag.py         # SelfRAG - —Å–∞–º–æ–æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ cove.py             # ChainOfVerification - –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è
‚îÇ       ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ utils/                  # –£—Ç–∏–ª–∏—Ç—ã
‚îÇ           ‚îú‚îÄ‚îÄ __init__.py
‚îÇ           ‚îú‚îÄ‚îÄ tracing.py          # TracingManager - —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ pipeline
‚îÇ           ‚îî‚îÄ‚îÄ logging.py          # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ knowledge_base/             # –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π (markdown)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ grammar_verbs.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ grammar_articles.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ idioms_phrases.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ translation_difficulties.md
‚îÇ   ‚îî‚îÄ‚îÄ chroma_db/                  # –í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ (—Å–æ–∑–¥–∞—ë—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
‚îÇ
‚îú‚îÄ‚îÄ tests/                          # Pytest —Ç–µ—Å—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py
‚îÇ   ‚îú‚îÄ‚îÄ test_safety.py
‚îÇ   ‚îî‚îÄ‚îÄ test_enhancements.py
‚îÇ
‚îú‚îÄ‚îÄ logs/                           # –õ–æ–≥–∏ (—Å–æ–∑–¥–∞—ë—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
‚îú‚îÄ‚îÄ french_assistant.ipynb          # Jupyter Notebook –¥–ª—è Google Colab
‚îú‚îÄ‚îÄ pyproject.toml                  # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–∞–∫–µ—Ç–∞ (PEP 517/518)
‚îú‚îÄ‚îÄ requirements.txt                # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (legacy)
‚îî‚îÄ‚îÄ README.md
```

### –ú–æ–¥—É–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

| –ú–æ–¥—É–ª—å | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ |
|--------|------------|
| `core` | –ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å `FrenchAssistant` –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è |
| `safety` | –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –¥–µ—Ç–µ–∫—Ü–∏—è –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π |
| `retrieval` | –ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤, —Ä–∞–±–æ—Ç–∞ —Å –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î |
| `enhancements` | RAG-—É–ª—É—á—à–µ–Ω–∏—è: CRAG, Self-RAG, Chain-of-Verification |
| `utils` | –¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ |

---

## üìà –ú–µ—Ç—Ä–∏–∫–∏ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

### Tracing

–°–∏—Å—Ç–µ–º–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫—É –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞:

```
[14:23:45.123] SafetyFilter -> safety_passed
  Input: "–ü–µ—Ä–µ–≤–µ–¥–∏: –ü—Ä–∏–≤–µ—Ç..."
  Output: safe
[14:23:45.456] EnhancedRetriever -> query_expansion  
  Input: "–ü–µ—Ä–µ–≤–µ–¥–∏: –ü—Ä–∏–≤–µ—Ç"
  Output: 4 variants
[14:23:46.789] EnhancedRetriever -> retrieval_complete
  Input: 4 queries
  Output: 3 documents retrieved
```

### –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏

- **Grounding Score:** –ø—Ä–æ—Ü–µ–Ω—Ç —Ç–µ—Ä–º–∏–Ω–æ–≤ –æ—Ç–≤–µ—Ç–∞, –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
- **Consistency Score:** –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π
- **Utility Score:** –ø–æ–ª–µ–∑–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
- **Overall Quality:** –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞

---

## üîÆ Roadmap

- [ ] –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Saiga LLaMA3 8B
- [ ] Web-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å (Gradio/Streamlit)
- [ ] –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
- [ ] A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤
- [ ] Fine-tuning –Ω–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∫–æ—Ä–ø—É—Å–∞—Ö
- [ ] –ì–æ–ª–æ—Å–æ–≤–æ–π –≤–≤–æ–¥/–≤—ã–≤–æ–¥

---

## üõ† –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏

### –û—Å–Ω–æ–≤–Ω–æ–π —Å—Ç–µ–∫

| –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è | –í–µ—Ä—Å–∏—è | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ |
|------------|--------|------------|
| **Python** | 3.10+ | –û—Å–Ω–æ–≤–Ω–æ–π —è–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è |
| **LangChain** | >= 0.2 | –§—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è RAG-—Å–∏—Å—Ç–µ–º |
| **ChromaDB** | >= 0.4 | –í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ |
| **Sentence-Transformers** | >= 2.2 | –ú—É–ª—å—Ç–∏—è–∑—ã—á–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ |
| **Transformers** | >= 4.35 | –†–∞–±–æ—Ç–∞ —Å LLM –º–æ–¥–µ–ª—è–º–∏ |
| **PyTorch** | >= 2.0 | –§—Ä–µ–π–º–≤–æ—Ä–∫ –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è |

### LangChain –º–æ–¥—É–ª–∏

- `langchain-core` ‚Äî –±–∞–∑–æ–≤—ã–µ –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–∏ –∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã
- `langchain-community` ‚Äî –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –≤–Ω–µ—à–Ω–∏–º–∏ —Å–µ—Ä–≤–∏—Å–∞–º–∏
- `langchain-text-splitters` ‚Äî —Ä–∞–∑–±–∏–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∞ chunks
- `langchain-huggingface` ‚Äî –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å HuggingFace

### –ú–æ–¥–µ–ª–∏

| –ú–æ–¥–µ–ª—å | –¢–∏–ø | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ |
|--------|-----|------------|
| `paraphrase-multilingual-MiniLM-L12-v2` | Embeddings | –ú—É–ª—å—Ç–∏—è–∑—ã—á–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ (RU/FR) |
| `IlyaGusev/saiga_llama3_8b` | LLM | –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ (—Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω–∞—è) |
| `cross-encoder/ms-marco-MiniLM-L-6-v2` | Re-ranker | –ü–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ |

### RAG-—Ç–µ—Ö–Ω–∏–∫–∏

- **Query Expansion** ‚Äî —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤ —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏
- **HyDE** (Hypothetical Document Embeddings) ‚Äî –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≥–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
- **MMR** (Maximum Marginal Relevance) ‚Äî –±–∞–ª–∞–Ω—Å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
- **CRAG** (Corrective RAG) ‚Äî –∫–æ—Ä—Ä–µ–∫—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ retrieval
- **Self-RAG** ‚Äî —Å–∞–º–æ–æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
- **CoVe** (Chain of Verification) ‚Äî –ø–æ—à–∞–≥–æ–≤–∞—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤

### –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏

- `pytest` ‚Äî —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
- `black` ‚Äî —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞
- `mypy` ‚Äî —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∞—è —Ç–∏–ø–∏–∑–∞—Ü–∏—è
- `PyYAML` ‚Äî –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

---

## üìö –ü–æ–ª–µ–∑–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã

### RAG from Scratch

–ü—Ä–æ–µ–∫—Ç –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –∫–æ–Ω—Ü–µ–ø—Ü–∏—è—Ö –∏–∑ –∫—É—Ä—Å–∞ **RAG from Scratch** –æ—Ç LangChain:

üîó **[langchain-ai/rag-from-scratch](https://github.com/langchain-ai/rag-from-scratch)**

<img src="images/RAG_map.png" width="512" height="512">

–ö—É—Ä—Å –æ—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç:
- –û—Å–Ω–æ–≤—ã RAG-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
- Query Translation (Multi-query, RAG-Fusion, Decomposition, Step-back, HyDE)
- Routing (Logical –∏ Semantic routing)
- Query Construction (Text-to-SQL, Text-to-Cypher)
- Indexing (Multi-representation, RAPTOR, ColBERT)
- Retrieval (Re-ranking, CRAG, Self-RAG, Adaptive RAG)

### –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [LangChain Documentation](https://python.langchain.com/docs/)
- [ChromaDB Documentation](https://docs.trychroma.com/)
- [Sentence-Transformers](https://www.sbert.net/)
- [Saiga Models](https://huggingface.co/IlyaGusev)
- [–°—Ç–∞—Ç—å—è –Ω–∞ Habr –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é –Ω–µ–π—Ä–æ-—Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –æ—Ç –∞–∫–∞–¥–µ–º–∏–∏ The Founder](https://habr.com/ru/articles/825220/)
- [–ü—Ä–∏–º–µ—Ä —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω–æ–π LLM](https://huggingface.co/IlyaGusev/saiga_llama3_8b)
---

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

MIT License

---

<div align="center">

**–°–¥–µ–ª–∞–Ω–æ —Å ‚ù§Ô∏è –¥–ª—è –∏–∑—É—á–∞—é—â–∏—Ö —Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π —è–∑—ã–∫**

</div>
